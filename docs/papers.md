---
title: "Papers"
sidebar_position: 999
---

# Academic Papers

Key research papers in AI and language models with direct links to sources.

## Foundation Models

**LLaMA: Open and Efficient Foundation Language Models** (2023)  
[arXiv](https://arxiv.org/abs/2302.13971) | Meta AI  
*LLaMA-13B outperforms GPT-3 (175B) using only public data*

**LLaMA 2: Open Foundation and Fine-Tuned Chat Models** (2023)  
[arXiv](https://arxiv.org/abs/2307.09288) | Meta AI  
*First open-source models with commercial license and safety focus*

**Gemma: Open Models Based on Gemini Research** (2024)  
[arXiv](https://arxiv.org/abs/2403.08295) | Google  
*Efficient 2B and 7B models ideal for edge computing*

## Architecture

**Attention Is All You Need** (2017)  
[arXiv](https://arxiv.org/abs/1706.03762) | Google  
*Introduced Transformer architecture, foundation of all modern LLMs*

## Safety & Alignment

**A Survey on Hallucination in Large Language Models** (2023)  
[arXiv](https://arxiv.org/abs/2311.05232)  
*Systematic analysis of LLM hallucination problems and solutions*

**Theory of Mind in Large Language Models** (2023)  
[arXiv](https://arxiv.org/abs/2302.02083) | Stanford  
*Evidence of emergent cognitive abilities in GPT models*

## Applications

**ChatGPT and Software Testing Education** (2023)  
[arXiv](https://arxiv.org/abs/2302.03287)  
*Evaluation of LLMs in software testing tasks*

**Faith and Fate: Limits of Transformers on Compositionality** (2023)  
[arXiv](https://arxiv.org/abs/2305.18654)  
*Fundamental limitations in compositional reasoning*

## Philosophy

**The Illusion of Thinking: Cognitive Science of LLMs** (2023)  
[arXiv](https://arxiv.org/abs/2301.10169)  
*Philosophical analysis of whether LLMs truly "think"*

**A Survey on Large Language Models** (2023)  
[arXiv](https://arxiv.org/abs/2303.18223)  
*Comprehensive review of LLM evolution from BERT to ChatGPT*
